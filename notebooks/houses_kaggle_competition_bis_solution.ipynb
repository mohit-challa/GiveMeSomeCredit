{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import set_config; set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Houses Kaggle Competition (bis üî•) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src='https://github.com/lewagon/data-images/blob/master/ML/kaggle-batch-challenge.png?raw=true' width=600>](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "Let's re-use our previous pipeline build in module `05-07-Ensemble-Methods` and improve final predictions using a Neural Network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-use already-built preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 80) (1460,) (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "# Let's load our training dataset\n",
    "data = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_train_raw.csv\")\n",
    "X = data.drop(columns='SalePrice')\n",
    "y = data['SalePrice']\n",
    "\n",
    "# You don't have access to y_yest! Only Kaggle has it.\n",
    "X_test = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_test_raw.csv\")\n",
    "\n",
    "print(X.shape, y.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find in `utils/preprocessor.py` the data-preprocessing pipeline that was built in our previous iteration.\n",
    "\n",
    "‚ùì Run the cell below, and make sure you understand what the pipeline does. Look at the code in `preprocessor.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0a8cf29f-6de4-43b0-a6e2-cd386dbcde77\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0a8cf29f-6de4-43b0-a6e2-cd386dbcde77\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('numerical_encoder',\n",
       "                                                  Pipeline(steps=[('knnimputer',\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  ('minmaxscaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['1stFlrSF', '2ndFlrSF',\n",
       "                                                   '3SsnPorch', 'BedroomAbvGr',\n",
       "                                                   'BsmtFinSF1', 'BsmtFinSF2',\n",
       "                                                   'BsmtFullBath',\n",
       "                                                   'BsmtHalfBath', 'BsmtUnfSF',\n",
       "                                                   'EnclosedPorch',\n",
       "                                                   'Fireplaces', 'FullBath',\n",
       "                                                   'GarageArea', 'GarageCars...\n",
       "                                                   'CentralAir', 'Condition1',\n",
       "                                                   'Condition2', 'Exterior1st',\n",
       "                                                   'Exterior2nd', 'Foundation',\n",
       "                                                   'GarageType', 'Heating',\n",
       "                                                   'HouseStyle', 'LotConfig',\n",
       "                                                   'MSZoning', 'MasVnrType',\n",
       "                                                   'MiscFeature',\n",
       "                                                   'Neighborhood', 'RoofMatl',\n",
       "                                                   'RoofStyle', 'SaleCondition',\n",
       "                                                   'SaleType', 'Street',\n",
       "                                                   'Utilities'])])),\n",
       "                ('selectpercentile',\n",
       "                 SelectPercentile(percentile=75,\n",
       "                                  score_func=<function mutual_info_regression at 0x1468e7af0>))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"70233bb7-864e-4eaf-a30a-0d31de33c8ca\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"70233bb7-864e-4eaf-a30a-0d31de33c8ca\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('numerical_encoder',\n",
       "                                 Pipeline(steps=[('knnimputer', KNNImputer()),\n",
       "                                                 ('minmaxscaler',\n",
       "                                                  MinMaxScaler())]),\n",
       "                                 ['1stFlrSF', '2ndFlrSF', '3SsnPorch',\n",
       "                                  'BedroomAbvGr', 'BsmtFinSF1', 'BsmtFinSF2',\n",
       "                                  'BsmtFullBath', 'BsmtHalfBath', 'BsmtUnfSF',\n",
       "                                  'EnclosedPorch', 'Fireplaces', 'FullBath',\n",
       "                                  'GarageArea', 'GarageCars', 'GarageYrBlt',\n",
       "                                  'GrLivArea', 'HalfBath...\n",
       "                                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 ['Alley', 'BldgType', 'CentralAir',\n",
       "                                  'Condition1', 'Condition2', 'Exterior1st',\n",
       "                                  'Exterior2nd', 'Foundation', 'GarageType',\n",
       "                                  'Heating', 'HouseStyle', 'LotConfig',\n",
       "                                  'MSZoning', 'MasVnrType', 'MiscFeature',\n",
       "                                  'Neighborhood', 'RoofMatl', 'RoofStyle',\n",
       "                                  'SaleCondition', 'SaleType', 'Street',\n",
       "                                  'Utilities'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0e4fdca1-7274-45ef-b99f-58f2944d16d5\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0e4fdca1-7274-45ef-b99f-58f2944d16d5\">numerical_encoder</label><div class=\"sk-toggleable__content\"><pre>['1stFlrSF', '2ndFlrSF', '3SsnPorch', 'BedroomAbvGr', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtUnfSF', 'EnclosedPorch', 'Fireplaces', 'FullBath', 'GarageArea', 'GarageCars', 'GarageYrBlt', 'GrLivArea', 'HalfBath', 'Id', 'KitchenAbvGr', 'LotArea', 'LotFrontage', 'LowQualFinSF', 'MSSubClass', 'MasVnrArea', 'MiscVal', 'MoSold', 'OpenPorchSF', 'OverallCond', 'OverallQual', 'PoolArea', 'ScreenPorch', 'TotRmsAbvGrd', 'TotalBsmtSF', 'WoodDeckSF', 'YearBuilt', 'YearRemodAdd', 'YrSold']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f0d5300f-ae08-4f51-81fd-e37241d598f6\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"f0d5300f-ae08-4f51-81fd-e37241d598f6\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"52410bc3-8ea6-4397-ad05-4e3687b5c4ed\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"52410bc3-8ea6-4397-ad05-4e3687b5c4ed\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b3736e58-7e5f-4f63-9f71-1f1b232c4838\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b3736e58-7e5f-4f63-9f71-1f1b232c4838\">ordinal_encoder</label><div class=\"sk-toggleable__content\"><pre>['BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', 'Electrical', 'ExterCond', 'ExterQual', 'Fence', 'FireplaceQu', 'Functional', 'GarageCond', 'GarageFinish', 'GarageQual', 'HeatingQC', 'KitchenQual', 'LandContour', 'LandSlope', 'LotShape', 'PavedDrive', 'PoolQC']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"164adad0-1572-46a7-bff0-22c0e1877ee4\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"164adad0-1572-46a7-bff0-22c0e1877ee4\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value='missing', strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e02c23ac-c840-4da5-8f11-3dc3f7538fc3\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e02c23ac-c840-4da5-8f11-3dc3f7538fc3\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(categories=[['missing', 'Po', 'Fa', 'TA', 'Gd'],\n",
       "                           ['missing', 'No', 'Mn', 'Av', 'Gd'],\n",
       "                           ['missing', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ',\n",
       "                            'GLQ'],\n",
       "                           ['missing', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ',\n",
       "                            'GLQ'],\n",
       "                           ['missing', 'Fa', 'TA', 'Gd', 'Ex'],\n",
       "                           ['missing', 'Mix', 'FuseP', 'FuseF', 'FuseA',\n",
       "                            'SBrkr'],\n",
       "                           ['missing', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
       "                           ['missing', 'Fa', 'TA', 'Gd', 'Ex'],\n",
       "                           ['missing', '...\n",
       "                           ['missing', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
       "                           ['missing', 'Unf', 'RFn', 'Fin'],\n",
       "                           ['missing', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
       "                           ['missing', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
       "                           ['missing', 'Fa', 'TA', 'Gd', 'Ex'],\n",
       "                           ['missing', 'Low', 'Bnk', 'HLS', 'Lvl'],\n",
       "                           ['missing', 'Sev', 'Mod', 'Gtl'],\n",
       "                           ['missing', 'IR3', 'IR2', 'IR1', 'Reg'],\n",
       "                           ['missing', 'N', 'P', 'Y'],\n",
       "                           ['missing', 'Fa', 'Gd', 'Ex']],\n",
       "               handle_unknown='use_encoded_value', unknown_value=-1)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"cb74a72e-c849-4501-88fb-9e094dbd3ab9\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"cb74a72e-c849-4501-88fb-9e094dbd3ab9\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0fbd4f01-9983-4b40-9cfc-37d0b44303f0\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0fbd4f01-9983-4b40-9cfc-37d0b44303f0\">nominal_encoder</label><div class=\"sk-toggleable__content\"><pre>['Alley', 'BldgType', 'CentralAir', 'Condition1', 'Condition2', 'Exterior1st', 'Exterior2nd', 'Foundation', 'GarageType', 'Heating', 'HouseStyle', 'LotConfig', 'MSZoning', 'MasVnrType', 'MiscFeature', 'Neighborhood', 'RoofMatl', 'RoofStyle', 'SaleCondition', 'SaleType', 'Street', 'Utilities']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"43781198-6310-4b24-a777-e56a866d453b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"43781198-6310-4b24-a777-e56a866d453b\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='most_frequent')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"624348b0-6073-44fa-971f-aabe20dd1664\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"624348b0-6073-44fa-971f-aabe20dd1664\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0034c3a6-54a1-456e-901f-e11dee7d7a7f\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0034c3a6-54a1-456e-901f-e11dee7d7a7f\">SelectPercentile</label><div class=\"sk-toggleable__content\"><pre>SelectPercentile(percentile=75,\n",
       "                 score_func=<function mutual_info_regression at 0x1468e7af0>)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('numerical_encoder',\n",
       "                                                  Pipeline(steps=[('knnimputer',\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  ('minmaxscaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['1stFlrSF', '2ndFlrSF',\n",
       "                                                   '3SsnPorch', 'BedroomAbvGr',\n",
       "                                                   'BsmtFinSF1', 'BsmtFinSF2',\n",
       "                                                   'BsmtFullBath',\n",
       "                                                   'BsmtHalfBath', 'BsmtUnfSF',\n",
       "                                                   'EnclosedPorch',\n",
       "                                                   'Fireplaces', 'FullBath',\n",
       "                                                   'GarageArea', 'GarageCars...\n",
       "                                                   'CentralAir', 'Condition1',\n",
       "                                                   'Condition2', 'Exterior1st',\n",
       "                                                   'Exterior2nd', 'Foundation',\n",
       "                                                   'GarageType', 'Heating',\n",
       "                                                   'HouseStyle', 'LotConfig',\n",
       "                                                   'MSZoning', 'MasVnrType',\n",
       "                                                   'MiscFeature',\n",
       "                                                   'Neighborhood', 'RoofMatl',\n",
       "                                                   'RoofStyle', 'SaleCondition',\n",
       "                                                   'SaleType', 'Street',\n",
       "                                                   'Utilities'])])),\n",
       "                ('selectpercentile',\n",
       "                 SelectPercentile(percentile=75,\n",
       "                                  score_func=<function mutual_info_regression at 0x1468e7af0>))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.preprocessor import create_preproc\n",
    "preproc = create_preproc(X)\n",
    "preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Fit the preprocessor you your train set and create your feature matrix `X_preproc` that will be used by the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 162)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the preprocessor on the train set\n",
    "preproc.fit(X, y)\n",
    "\n",
    "# create \n",
    "X_preproc = preproc.transform(X)\n",
    "X_preproc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your prediction in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is your first **regression** task with Keras! \n",
    "- The cell below contains compiler and fit hyper-parameters we recommend you to start with.\n",
    "- Kaggle's [rule](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/evaluation) requires to minimize `rmsle` (Root Mean Square Log Error). As you can see, we have been able to specify `msle` direcly as loss-function with Keras! Just remember to take square-root of your loss results to read your rmsle metric.\n",
    "- The best boosted-tree `rmsle` score to beat is around **0.13**\n",
    "\n",
    "‚ùì **Question** ‚ùì\n",
    "- Your responsibility is to build the best model architecture, and to control the epoch number to avoid overfitting.\n",
    "- We recommand you to create a train/val split upfront to visually control the validation loss thanks to `plot_history`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train val split here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "\n",
    "    ### YOUR MODEL ARCHITECTURE HERE\n",
    "    # model = ...\n",
    "\n",
    "    \n",
    "    # Recommended compilator\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='msle', # directly optimize for the squared log error!\n",
    "    return model\n",
    "\n",
    "model = initialize_model()\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=100, # Play with this until your validation loss overfit\n",
    "                    batch_size=16, # Keep batch size to 16 today\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.plot(np.sqrt(history.history['loss']))\n",
    "    plt.plot(np.sqrt(history.history['val_loss']))\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('MSLE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_preproc,y,test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(X):\n",
    "\n",
    "    # Model architecture\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(20, activation='relu', input_dim=X.shape[1]))\n",
    "    model.add(layers.Dense(15, activation='relu'))\n",
    "    model.add(layers.Dense(15, activation='relu'))\n",
    "    model.add(layers.Dense(20, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    \n",
    "    # Recommended compilator hyperparams\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='msle', # we directly optimize for the kaggle's metric!\n",
    "    ) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_110 (Dense)            (None, 20)                3260      \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 20)                320       \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 4,156\n",
      "Trainable params: 4,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model(X_train)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 120.8843 - val_loss: 78.1758\n",
      "Epoch 2/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 71.0888 - val_loss: 53.4854\n",
      "Epoch 3/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 49.5915 - val_loss: 39.0685\n",
      "Epoch 4/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 36.5644 - val_loss: 29.2165\n",
      "Epoch 5/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 27.5204 - val_loss: 22.8239\n",
      "Epoch 6/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 21.6336 - val_loss: 18.3738\n",
      "Epoch 7/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 17.7563 - val_loss: 15.0812\n",
      "Epoch 8/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 14.5296 - val_loss: 12.5518\n",
      "Epoch 9/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 12.0842 - val_loss: 10.5517\n",
      "Epoch 10/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 10.1986 - val_loss: 8.8509\n",
      "Epoch 11/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 8.6538 - val_loss: 7.2813\n",
      "Epoch 12/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 7.0481 - val_loss: 6.0160\n",
      "Epoch 13/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 5.8372 - val_loss: 5.0062\n",
      "Epoch 14/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 4.9225 - val_loss: 4.1928\n",
      "Epoch 15/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 4.1294 - val_loss: 3.5253\n",
      "Epoch 16/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 3.3962 - val_loss: 2.9770\n",
      "Epoch 17/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 2.8663 - val_loss: 2.5203\n",
      "Epoch 18/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 2.4913 - val_loss: 2.1376\n",
      "Epoch 19/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 2.1446 - val_loss: 1.8157\n",
      "Epoch 20/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.8401 - val_loss: 1.5452\n",
      "Epoch 21/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.5813 - val_loss: 1.3166\n",
      "Epoch 22/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.2912 - val_loss: 1.1227\n",
      "Epoch 23/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.1353 - val_loss: 0.9575\n",
      "Epoch 24/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.9545 - val_loss: 0.8172\n",
      "Epoch 25/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.8111 - val_loss: 0.6988\n",
      "Epoch 26/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7022 - val_loss: 0.5978\n",
      "Epoch 27/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6243 - val_loss: 0.5126\n",
      "Epoch 28/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.5355 - val_loss: 0.4405\n",
      "Epoch 29/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.4314 - val_loss: 0.3802\n",
      "Epoch 30/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.3936 - val_loss: 0.3286\n",
      "Epoch 31/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.3380 - val_loss: 0.2860\n",
      "Epoch 32/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.2501\n",
      "Epoch 33/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.2715 - val_loss: 0.2203\n",
      "Epoch 34/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.2533 - val_loss: 0.1956\n",
      "Epoch 35/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.2103 - val_loss: 0.1755\n",
      "Epoch 36/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1872 - val_loss: 0.1588\n",
      "Epoch 37/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1684 - val_loss: 0.1451\n",
      "Epoch 38/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1493 - val_loss: 0.1338\n",
      "Epoch 39/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1318 - val_loss: 0.1249\n",
      "Epoch 40/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1338 - val_loss: 0.1177\n",
      "Epoch 41/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1244 - val_loss: 0.1119\n",
      "Epoch 42/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1192 - val_loss: 0.1073\n",
      "Epoch 43/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1124 - val_loss: 0.1039\n",
      "Epoch 44/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1173 - val_loss: 0.1009\n",
      "Epoch 45/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1066 - val_loss: 0.0988\n",
      "Epoch 46/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1168 - val_loss: 0.0970\n",
      "Epoch 47/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1027 - val_loss: 0.0957\n",
      "Epoch 48/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1095 - val_loss: 0.0947\n",
      "Epoch 49/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1098 - val_loss: 0.0939\n",
      "Epoch 50/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1064 - val_loss: 0.0932\n",
      "Epoch 51/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0842 - val_loss: 0.0927\n",
      "Epoch 52/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0972 - val_loss: 0.0922\n",
      "Epoch 53/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1067 - val_loss: 0.0918\n",
      "Epoch 54/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0883 - val_loss: 0.0914\n",
      "Epoch 55/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0897 - val_loss: 0.0910\n",
      "Epoch 56/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0941 - val_loss: 0.0906\n",
      "Epoch 57/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0923 - val_loss: 0.0903\n",
      "Epoch 58/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1055 - val_loss: 0.0899\n",
      "Epoch 59/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0953 - val_loss: 0.0895\n",
      "Epoch 60/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0927 - val_loss: 0.0891\n",
      "Epoch 61/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0968 - val_loss: 0.0887\n",
      "Epoch 62/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0945 - val_loss: 0.0883\n",
      "Epoch 63/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.0879\n",
      "Epoch 64/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0943 - val_loss: 0.0874\n",
      "Epoch 65/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.0869\n",
      "Epoch 66/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.1019 - val_loss: 0.0864\n",
      "Epoch 67/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0929 - val_loss: 0.0859\n",
      "Epoch 68/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0915 - val_loss: 0.0853\n",
      "Epoch 69/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0828 - val_loss: 0.0848\n",
      "Epoch 70/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0894 - val_loss: 0.0843\n",
      "Epoch 71/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0837\n",
      "Epoch 72/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0829 - val_loss: 0.0831\n",
      "Epoch 73/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0857 - val_loss: 0.0826\n",
      "Epoch 74/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.0820\n",
      "Epoch 75/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0876 - val_loss: 0.0814\n",
      "Epoch 76/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0807\n",
      "Epoch 77/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0928 - val_loss: 0.0800\n",
      "Epoch 78/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0914 - val_loss: 0.0794\n",
      "Epoch 79/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0894 - val_loss: 0.0786\n",
      "Epoch 80/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.0779\n",
      "Epoch 81/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0789 - val_loss: 0.0772\n",
      "Epoch 82/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.0756\n",
      "Epoch 84/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0944 - val_loss: 0.0748\n",
      "Epoch 85/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0827 - val_loss: 0.0740\n",
      "Epoch 86/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0732\n",
      "Epoch 87/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0816 - val_loss: 0.0723\n",
      "Epoch 88/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0845 - val_loss: 0.0714\n",
      "Epoch 89/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0706\n",
      "Epoch 90/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0696\n",
      "Epoch 91/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0779 - val_loss: 0.0688\n",
      "Epoch 92/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0677\n",
      "Epoch 93/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0668\n",
      "Epoch 94/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.0657\n",
      "Epoch 95/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0648\n",
      "Epoch 96/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0637\n",
      "Epoch 97/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0730 - val_loss: 0.0627\n",
      "Epoch 98/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0616\n",
      "Epoch 99/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.0605\n",
      "Epoch 100/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0593\n",
      "Epoch 101/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.0583\n",
      "Epoch 102/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.0570\n",
      "Epoch 103/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0644 - val_loss: 0.0560\n",
      "Epoch 104/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0648 - val_loss: 0.0547\n",
      "Epoch 105/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0536\n",
      "Epoch 106/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0562 - val_loss: 0.0524\n",
      "Epoch 107/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0617 - val_loss: 0.0511\n",
      "Epoch 108/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0616 - val_loss: 0.0499\n",
      "Epoch 109/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0488\n",
      "Epoch 110/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0475\n",
      "Epoch 111/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0463\n",
      "Epoch 112/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0468 - val_loss: 0.0451\n",
      "Epoch 113/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0485 - val_loss: 0.0439\n",
      "Epoch 114/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0471 - val_loss: 0.0428\n",
      "Epoch 115/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0470 - val_loss: 0.0417\n",
      "Epoch 116/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0444 - val_loss: 0.0407\n",
      "Epoch 117/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0395\n",
      "Epoch 118/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0384\n",
      "Epoch 119/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0375\n",
      "Epoch 120/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.0365\n",
      "Epoch 121/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.0358\n",
      "Epoch 122/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0373 - val_loss: 0.0350\n",
      "Epoch 123/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0375 - val_loss: 0.0341\n",
      "Epoch 124/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0390 - val_loss: 0.0333\n",
      "Epoch 125/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.0327\n",
      "Epoch 126/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0332 - val_loss: 0.0321\n",
      "Epoch 127/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0322 - val_loss: 0.0313\n",
      "Epoch 128/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.0310\n",
      "Epoch 129/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0339 - val_loss: 0.0303\n",
      "Epoch 130/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0308 - val_loss: 0.0298\n",
      "Epoch 131/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0293\n",
      "Epoch 132/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0295 - val_loss: 0.0290\n",
      "Epoch 133/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0318 - val_loss: 0.0283\n",
      "Epoch 134/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0296 - val_loss: 0.0281\n",
      "Epoch 135/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0292 - val_loss: 0.0276\n",
      "Epoch 136/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0302 - val_loss: 0.0271\n",
      "Epoch 137/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0300 - val_loss: 0.0269\n",
      "Epoch 138/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0316 - val_loss: 0.0265\n",
      "Epoch 139/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0287 - val_loss: 0.0262\n",
      "Epoch 140/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0304 - val_loss: 0.0258\n",
      "Epoch 141/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.0258\n",
      "Epoch 142/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0265 - val_loss: 0.0252\n",
      "Epoch 143/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0266 - val_loss: 0.0250\n",
      "Epoch 144/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0261 - val_loss: 0.0245\n",
      "Epoch 145/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.0242\n",
      "Epoch 146/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0256 - val_loss: 0.0239\n",
      "Epoch 147/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.0238\n",
      "Epoch 148/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0239 - val_loss: 0.0236\n",
      "Epoch 149/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0231 - val_loss: 0.0232\n",
      "Epoch 150/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.0230\n",
      "Epoch 151/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0253 - val_loss: 0.0228\n",
      "Epoch 152/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0227 - val_loss: 0.0227\n",
      "Epoch 153/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.0227\n",
      "Epoch 154/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0218 - val_loss: 0.0221\n",
      "Epoch 155/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0238 - val_loss: 0.0218\n",
      "Epoch 156/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.0217\n",
      "Epoch 157/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0239 - val_loss: 0.0218\n",
      "Epoch 158/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0217\n",
      "Epoch 159/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0214\n",
      "Epoch 160/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0210\n",
      "Epoch 161/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0236 - val_loss: 0.0208\n",
      "Epoch 162/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0208\n",
      "Epoch 163/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 164/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0223 - val_loss: 0.0206\n",
      "Epoch 165/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0207 - val_loss: 0.0202\n",
      "Epoch 166/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0203\n",
      "Epoch 167/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0198\n",
      "Epoch 168/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0198\n",
      "Epoch 169/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0197\n",
      "Epoch 170/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0197\n",
      "Epoch 171/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0195\n",
      "Epoch 172/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0201\n",
      "Epoch 173/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0191\n",
      "Epoch 174/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0191\n",
      "Epoch 175/500\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0191\n",
      "Epoch 176/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0188\n",
      "Epoch 177/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0186\n",
      "Epoch 178/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0191\n",
      "Epoch 179/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.0183\n",
      "Epoch 180/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0183\n",
      "Epoch 181/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0186\n",
      "Epoch 182/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0181\n",
      "Epoch 183/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0180\n",
      "Epoch 184/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0178\n",
      "Epoch 185/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0178\n",
      "Epoch 186/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0179\n",
      "Epoch 187/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0176\n",
      "Epoch 188/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 189/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0174\n",
      "Epoch 190/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0175\n",
      "Epoch 191/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0174\n",
      "Epoch 192/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 193/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0171\n",
      "Epoch 194/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0172\n",
      "Epoch 195/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0174\n",
      "Epoch 196/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0198 - val_loss: 0.0169\n",
      "Epoch 197/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0167\n",
      "Epoch 198/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0169\n",
      "Epoch 199/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0169\n",
      "Epoch 200/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0165\n",
      "Epoch 201/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0165\n",
      "Epoch 202/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0164\n",
      "Epoch 203/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0164\n",
      "Epoch 204/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0162\n",
      "Epoch 205/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0164\n",
      "Epoch 206/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0162\n",
      "Epoch 207/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0166\n",
      "Epoch 208/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0162\n",
      "Epoch 209/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0162\n",
      "Epoch 210/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0159\n",
      "Epoch 211/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0158\n",
      "Epoch 212/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0157\n",
      "Epoch 213/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0157\n",
      "Epoch 214/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0156\n",
      "Epoch 215/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0158\n",
      "Epoch 216/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0157\n",
      "Epoch 217/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0154\n",
      "Epoch 218/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0154\n",
      "Epoch 219/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0153\n",
      "Epoch 220/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0154\n",
      "Epoch 221/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0154\n",
      "Epoch 222/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0157\n",
      "Epoch 223/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0153\n",
      "Epoch 224/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0159\n",
      "Epoch 225/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0163\n",
      "Epoch 226/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0151\n",
      "Epoch 227/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0149\n",
      "Epoch 228/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0149\n",
      "Epoch 229/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0148\n",
      "Epoch 230/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0148\n",
      "Epoch 231/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 232/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0152\n",
      "Epoch 233/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0150\n",
      "Epoch 234/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0147\n",
      "Epoch 235/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0152\n",
      "Epoch 236/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0146\n",
      "Epoch 237/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.0146\n",
      "Epoch 238/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.0145\n",
      "Epoch 239/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.0144\n",
      "Epoch 240/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 241/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0144\n",
      "Epoch 242/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0147\n",
      "Epoch 243/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0144\n",
      "Epoch 244/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.0144\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0144\n",
      "Epoch 246/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.0143\n",
      "Epoch 247/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0147\n",
      "Epoch 248/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 249/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0141\n",
      "Epoch 250/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0144\n",
      "Epoch 251/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0140\n",
      "Epoch 252/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 253/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.0141\n",
      "Epoch 254/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.0142\n",
      "Epoch 255/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0139\n",
      "Epoch 256/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0139\n",
      "Epoch 257/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0140\n",
      "Epoch 258/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 259/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0139\n",
      "Epoch 260/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0138\n",
      "Epoch 261/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0138\n",
      "Epoch 262/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.0138\n",
      "Epoch 263/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0142\n",
      "Epoch 264/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0139\n",
      "Epoch 265/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0139\n",
      "Epoch 266/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.0138\n",
      "Epoch 267/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0137\n",
      "Epoch 268/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0138\n",
      "Epoch 269/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0141\n",
      "Epoch 270/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0138\n",
      "Epoch 271/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.0138\n",
      "Epoch 272/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0139\n",
      "Epoch 273/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 274/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0136\n",
      "Epoch 275/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0144\n",
      "Epoch 276/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.0137\n",
      "Epoch 277/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0138\n",
      "Epoch 278/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0141\n",
      "Epoch 279/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.0137\n",
      "Epoch 280/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0137\n",
      "Epoch 281/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0137\n",
      "Epoch 282/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0138\n",
      "Epoch 283/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.0145\n",
      "Epoch 284/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0137\n",
      "Epoch 285/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0137\n",
      "Epoch 286/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0142\n",
      "Epoch 287/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0137\n",
      "Epoch 288/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0138\n",
      "Epoch 289/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0138\n",
      "Epoch 290/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0148\n",
      "Epoch 291/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0139\n",
      "Epoch 292/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0138\n",
      "Epoch 293/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0138\n",
      "Epoch 294/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0139\n",
      "Epoch 295/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.0138\n",
      "Epoch 296/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.0139\n",
      "Epoch 297/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0139\n",
      "Epoch 298/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0140\n",
      "Epoch 299/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0141\n",
      "Epoch 300/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0139\n",
      "Epoch 301/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0140\n",
      "Epoch 302/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0140\n",
      "Epoch 303/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0140\n",
      "Epoch 304/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0141\n",
      "Epoch 305/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0142\n",
      "Epoch 306/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0141\n",
      "Epoch 307/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0141\n",
      "Epoch 308/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0142\n",
      "Epoch 309/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0143\n",
      "Epoch 310/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0143\n",
      "Epoch 311/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0141\n",
      "Epoch 312/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0144\n",
      "Epoch 313/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0144\n",
      "Epoch 314/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0143\n",
      "Epoch 315/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 316/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0143\n",
      "Epoch 317/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0144\n",
      "Epoch 318/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0144\n",
      "Epoch 319/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.0146\n",
      "Epoch 320/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0144\n",
      "Epoch 321/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0144\n",
      "Epoch 322/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0146\n",
      "Epoch 323/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0144\n",
      "Epoch 324/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0145\n",
      "Epoch 325/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0146\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0146\n",
      "Epoch 327/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.0145\n",
      "Epoch 328/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0147\n",
      "Epoch 329/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0146\n",
      "Epoch 330/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0147\n",
      "Epoch 331/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0147\n",
      "Epoch 332/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0147\n",
      "Epoch 333/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0147\n",
      "Epoch 334/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0152\n",
      "Epoch 335/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0148\n",
      "Epoch 336/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0148\n",
      "Epoch 337/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0152\n",
      "Epoch 338/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0150\n",
      "Epoch 339/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0149\n",
      "Epoch 340/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0148\n",
      "Epoch 341/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0151\n",
      "Epoch 342/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0150\n",
      "Epoch 343/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0150\n",
      "Epoch 344/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0151\n",
      "Epoch 345/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0150\n",
      "Epoch 346/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0150\n",
      "Epoch 347/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0152\n",
      "Epoch 348/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0152\n",
      "Epoch 349/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0152\n",
      "Epoch 350/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0152\n",
      "Epoch 351/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0154\n",
      "Epoch 352/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0152\n",
      "Epoch 353/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0155\n",
      "Epoch 354/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0154\n",
      "Epoch 355/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0152\n",
      "Epoch 356/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0153\n",
      "Epoch 357/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0156\n",
      "Epoch 358/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0153\n",
      "Epoch 359/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0159\n",
      "Epoch 360/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0155\n",
      "Epoch 361/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0155\n",
      "Epoch 362/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0154\n",
      "Epoch 363/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0156\n",
      "Epoch 364/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0156\n",
      "Epoch 365/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0156\n",
      "Epoch 366/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0156\n",
      "Epoch 367/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0159\n",
      "Epoch 368/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0156\n",
      "Epoch 369/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0158\n",
      "Epoch 370/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0159\n",
      "Epoch 371/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0159\n",
      "Epoch 372/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0156\n",
      "Epoch 373/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.0159\n",
      "Epoch 374/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0158\n",
      "Epoch 375/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0160\n",
      "Epoch 376/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0158\n",
      "Epoch 377/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0159\n",
      "Epoch 378/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0159\n",
      "Epoch 379/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0163\n",
      "Epoch 380/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0159\n",
      "Epoch 381/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0161\n",
      "Epoch 382/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0160\n",
      "Epoch 383/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0168\n",
      "Epoch 384/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0159\n",
      "Epoch 385/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0161\n",
      "Epoch 386/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0162\n",
      "Epoch 387/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0160\n",
      "Epoch 388/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0162\n",
      "Epoch 389/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0162\n",
      "Epoch 390/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0161\n",
      "Epoch 391/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0162\n",
      "Epoch 392/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0167\n",
      "Epoch 393/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0163\n",
      "Epoch 394/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0162\n",
      "Epoch 395/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0162\n",
      "Epoch 396/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0166\n",
      "Epoch 397/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0163\n",
      "Epoch 398/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0164\n",
      "Epoch 399/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0164\n",
      "Epoch 400/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0165\n",
      "Epoch 401/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0163\n",
      "Epoch 402/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0164\n",
      "Epoch 403/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0169\n",
      "Epoch 404/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0165\n",
      "Epoch 405/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0167\n",
      "Epoch 406/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0164\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0165\n",
      "Epoch 408/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0167\n",
      "Epoch 409/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0166\n",
      "Epoch 410/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0167\n",
      "Epoch 411/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0168\n",
      "Epoch 412/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0166\n",
      "Epoch 413/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0167\n",
      "Epoch 414/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0167\n",
      "Epoch 415/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0176\n",
      "Epoch 416/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0171\n",
      "Epoch 417/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0169\n",
      "Epoch 418/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0172\n",
      "Epoch 419/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0169\n",
      "Epoch 420/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0170\n",
      "Epoch 421/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0171\n",
      "Epoch 422/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0169\n",
      "Epoch 423/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0170\n",
      "Epoch 424/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0171\n",
      "Epoch 425/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0171\n",
      "Epoch 426/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0172\n",
      "Epoch 427/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0172\n",
      "Epoch 428/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0174\n",
      "Epoch 429/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0180\n",
      "Epoch 430/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0171\n",
      "Epoch 431/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0174\n",
      "Epoch 432/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0172\n",
      "Epoch 433/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0175\n",
      "Epoch 434/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0174\n",
      "Epoch 435/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0175\n",
      "Epoch 436/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0176\n",
      "Epoch 437/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0182\n",
      "Epoch 438/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0173\n",
      "Epoch 439/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0174\n",
      "Epoch 440/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0177\n",
      "Epoch 441/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0175\n",
      "Epoch 442/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0177\n",
      "Epoch 443/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0176\n",
      "Epoch 444/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0177\n",
      "Epoch 445/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0177\n",
      "Epoch 446/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0176\n",
      "Epoch 447/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0176\n",
      "Epoch 448/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0178\n",
      "Epoch 449/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0179\n",
      "Epoch 450/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0185\n",
      "Epoch 451/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0183\n",
      "Epoch 452/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0178\n",
      "Epoch 453/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0181\n",
      "Epoch 454/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0179\n",
      "Epoch 455/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0180\n",
      "Epoch 456/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0181\n",
      "Epoch 457/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0182\n",
      "Epoch 458/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0181\n",
      "Epoch 459/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0181\n",
      "Epoch 460/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0183\n",
      "Epoch 461/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0184\n",
      "Epoch 462/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0181\n",
      "Epoch 463/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0186\n",
      "Epoch 464/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0182\n",
      "Epoch 465/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0184\n",
      "Epoch 466/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0184\n",
      "Epoch 467/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0181\n",
      "Epoch 468/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0183\n",
      "Epoch 469/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0180\n",
      "Epoch 470/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0185\n",
      "Epoch 471/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0187\n",
      "Epoch 472/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0183\n",
      "Epoch 473/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0187\n",
      "Epoch 474/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0185\n",
      "Epoch 475/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0184\n",
      "Epoch 476/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0199\n",
      "Epoch 477/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0188\n",
      "Epoch 478/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0188\n",
      "Epoch 479/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0185\n",
      "Epoch 480/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0189\n",
      "Epoch 481/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0190\n",
      "Epoch 482/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0194\n",
      "Epoch 483/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0186\n",
      "Epoch 484/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0188\n",
      "Epoch 485/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0189\n",
      "Epoch 486/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0188\n",
      "Epoch 487/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0187\n",
      "Epoch 488/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0195\n",
      "Epoch 489/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0191\n",
      "Epoch 490/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0190\n",
      "Epoch 491/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0189\n",
      "Epoch 492/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0191\n",
      "Epoch 493/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0191\n",
      "Epoch 494/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0191\n",
      "Epoch 495/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0190\n",
      "Epoch 496/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0190\n",
      "Epoch 497/500\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0191\n",
      "Epoch 498/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0193\n",
      "Epoch 499/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0192\n",
      "Epoch 500/500\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0194\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val), # create a val set within your train set\n",
    "                    epochs=500, # Play with this until your validation loss overfit\n",
    "                    batch_size=16, # Keep batch size to 16 today\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 549us/step - loss: 0.0194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13920540325010203"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val RMSE at last epoch\n",
    "model.evaluate(X_val, y_val)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11681289403521361"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mininimal val RMSE reached amongst all epochs\n",
    "min(history.history['val_loss'])**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì\n",
    "- Are you satisfied with your score?\n",
    "- Before you publish it, ask yourself if you can trust it entirely? Has it been cross-validated? \n",
    "- Feel free to cross-validate it manually with a for loop in python if you want before submitting to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X,y,train_index,val_index):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    model = initialize_model(X_train)\n",
    "    history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    epochs=500,\n",
    "                    batch_size=16,\n",
    "                    verbose=0)\n",
    "    return pd.DataFrame({\n",
    "        'rmsle_final_epoch': [model.evaluate(X_val, y_val)**0.5],\n",
    "        'rmsle_min': [min(history.history['val_loss'])**0.5]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "cv = 5\n",
    "kf = KFold(n_splits=cv, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 588us/step - loss: 9.7154\n",
      "12/12 [==============================] - 0s 738us/step - loss: 13.4770\n",
      "12/12 [==============================] - 0s 565us/step - loss: 9.8880\n",
      "12/12 [==============================] - 0s 711us/step - loss: 9.6846\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_preproc):\n",
    "    results.append(evaluate_model(X_preproc, y, train_index, val_index))\n",
    "    \n",
    "pd.concat(results, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BONUS SOLUTION**: Multiprocessing using [dask](https://docs.dask.org/en/latest/delayed.html) and 8 CPU cores to mimic sklearn's `n_jobs=-1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmsle</th>\n",
       "      <th>rmsle_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145304</td>\n",
       "      <td>0.137357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.141892</td>\n",
       "      <td>0.123132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.139644</td>\n",
       "      <td>0.132616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.137125</td>\n",
       "      <td>0.135550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167325</td>\n",
       "      <td>0.156293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rmsle  rmsle_min\n",
       "0  0.145304   0.137357\n",
       "0  0.141892   0.123132\n",
       "0  0.139644   0.132616\n",
       "0  0.137125   0.135550\n",
       "0  0.167325   0.156293"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install --quiet dask\n",
    "from dask import delayed\n",
    "\n",
    "f = delayed(evaluate_model)\n",
    "\n",
    "results = delayed(\n",
    "    [f(X_preproc, y, train_index, val_index) \n",
    "     for (train_index, val_index) in kf.split(X_preproc)]\n",
    ").compute(\n",
    "    scheduler='processes',\n",
    "    num_workers=8)\n",
    "\n",
    "pd.concat(results, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: multiprocessing with default python libray\n",
    "References [here](https://towardsdatascience.com/speeding-up-and-perfecting-your-work-using-parallel-computing-8bc2f0c073f8) and [here](https://johaupt.github.io/python/parallel%20processing/cross-validation/multiprocessing_cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing as mp\n",
    "# pool = mp.Pool(processes=2) #mp.cpu_count()-1)\n",
    "\n",
    "# results = []\n",
    "# def log_result(x):\n",
    "#     results.append(x)\n",
    "    \n",
    "# for train_index, val_index in kf.split(X_preproc):\n",
    "#     pool.apply_async(\n",
    "#         evaluate_model,\n",
    "#         args=(X, y, train_index, val_index),\n",
    "#         callback = log_result)\n",
    "\n",
    "# # Close the pool for new tasks\n",
    "# pool.close()\n",
    "\n",
    "# # Wait for all tasks to complete at this point\n",
    "# pool.join()\n",
    "\n",
    "# result = pd.concat(results, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÖFINAL SUBMISSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the house prices of your test set and submit results to kaggle! Be carefull with the format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T14:05:37.861551Z",
     "start_time": "2021-01-27T14:04:03.536Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_test_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T14:05:37.867076Z",
     "start_time": "2021-01-27T14:04:03.680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112746.77],\n",
       "       [149050.45],\n",
       "       [180118.2 ],\n",
       "       ...,\n",
       "       [168149.66],\n",
       "       [117278.93],\n",
       "       [205957.58]], dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_preproc = preproc.transform(X_test)\n",
    "predictions = model.predict(X_test_preproc)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T14:05:37.872326Z",
     "start_time": "2021-01-27T14:04:04.056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>112746.773438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>149050.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>180118.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>193795.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>202063.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>80209.367188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>73900.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>168149.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>117278.929688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>205957.578125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  112746.773438\n",
       "1     1462  149050.453125\n",
       "2     1463  180118.203125\n",
       "3     1464  193795.671875\n",
       "4     1465  202063.234375\n",
       "...    ...            ...\n",
       "1454  2915   80209.367188\n",
       "1455  2916   73900.828125\n",
       "1456  2917  168149.656250\n",
       "1457  2918  117278.929688\n",
       "1458  2919  205957.578125\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat([X_test[\"Id\"], pd.Series(predictions[:,0], name=\"SalePrice\")], axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T14:05:37.877574Z",
     "start_time": "2021-01-27T14:04:04.248Z"
    }
   },
   "outputs": [],
   "source": [
    "# Export to Kaggle format submission and submit it online!\n",
    "results.to_csv(\"submission_final.csv\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.997px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
